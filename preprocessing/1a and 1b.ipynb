{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                     1\n",
       "index                                                          1\n",
       "name                                         Vietnamese Pho Soup\n",
       "ingredients    ['8 cups beef broth', '4 cups water', '1 yello...\n",
       "cuisine                                               Vietnamese\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('training_data_w_ingredients.csv', sep=';', error_bad_lines=False)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Count\n",
      "cuisine\n",
      "Chinese       60\n",
      "Greek         50\n",
      "Iberic        40\n",
      "Italian       50\n",
      "Thai          50\n",
      "Vietnamese    50\n",
      "french        50\n",
      "korean        50\n",
      "Name: ingredients, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Count\")\n",
    "print(df.groupby('cuisine')['ingredients'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General look up\n",
    "The goal is to get a first impression of the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'1\", 1635),\n",
       " (\"'2\", 789),\n",
       " ('cup', 729),\n",
       " ('teaspoon', 685),\n",
       " ('tablespoons', 605)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "df['ingredients'] = df['ingredients']\n",
    "Counter(\" \".join(df[\"ingredients\"]).split()).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these words are relevant for our further analysis of the Data.\n",
    "\n",
    "Let's have a look at the typical count of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     57\n",
       "2     59\n",
       "3     44\n",
       "4     70\n",
       "Name: ingredients, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ingredients'].str.split().str.len().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make it more intresting\n",
    "With scattertextplot we can visualize the words and the frequenz of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import\n",
    "import string\n",
    "%matplotlib inline\n",
    "import scattertext as st\n",
    "import re, io\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, hmean, norm\n",
    "import spacy\n",
    "import os, pkgutil, json, urllib\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error handling https://stackoverflow.com/questions/66149878/e053-could-not-read-config-cfg-resumeparser\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanTextList</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vietnamese Pho Soup</td>\n",
       "      <td>['8 cups beef broth', '4 cups water', '1 yello...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>beef broth water yellow onion cloves garlic ro...</td>\n",
       "      <td>[beef, broth, water, yellow, onion, cloves, ga...</td>\n",
       "      <td>(beef, broth, water, yellow, onion, cloves, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Vietnamese Chicken Meatballs</td>\n",
       "      <td>['1 pound ground chicken', '3 tablespoons fish...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>chicken fish sauce onion cloves garlic lemongr...</td>\n",
       "      <td>[chicken, fish, sauce, onion, cloves, garlic, ...</td>\n",
       "      <td>(chicken, fish, sauce, onion, cloves, garlic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Vietnamese Restaurant-Style Grilled Lemongrass...</td>\n",
       "      <td>['1 pound pork blade steaks (boneless, about 1...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>pork blade steaks boneless light brown sugar g...</td>\n",
       "      <td>[pork, blade, steaks, boneless, light, brown, ...</td>\n",
       "      <td>(pork, blade, steaks, boneless, light, brown, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Vietnamese Caramel Chicken</td>\n",
       "      <td>['1 pound chicken thighs (with skin, deboned)'...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>chicken thighs skin deboned oil cloves garlic ...</td>\n",
       "      <td>[chicken, thighs, skin, deboned, oil, cloves, ...</td>\n",
       "      <td>(chicken, thighs, skin, deboned, oil, cloves, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Cheater Vietnamese Pho (Pho Bo)</td>\n",
       "      <td>['3 marrow bones (beef bone)', '50 ounces beef...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>marrow bones beef bone beef water onion half g...</td>\n",
       "      <td>[marrow, bones, beef, bone, beef, water, onion...</td>\n",
       "      <td>(marrow, bones, beef, bone, beef, water, onion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                               name  \\\n",
       "0           1      1                                Vietnamese Pho Soup   \n",
       "1           2      2                       Vietnamese Chicken Meatballs   \n",
       "2           3      3  Vietnamese Restaurant-Style Grilled Lemongrass...   \n",
       "3           4      4                         Vietnamese Caramel Chicken   \n",
       "4           5      5                    Cheater Vietnamese Pho (Pho Bo)   \n",
       "\n",
       "                                         ingredients     cuisine  \\\n",
       "0  ['8 cups beef broth', '4 cups water', '1 yello...  Vietnamese   \n",
       "1  ['1 pound ground chicken', '3 tablespoons fish...  Vietnamese   \n",
       "2  ['1 pound pork blade steaks (boneless, about 1...  Vietnamese   \n",
       "3  ['1 pound chicken thighs (with skin, deboned)'...  Vietnamese   \n",
       "4  ['3 marrow bones (beef bone)', '50 ounces beef...  Vietnamese   \n",
       "\n",
       "                                           cleanText  \\\n",
       "0  beef broth water yellow onion cloves garlic ro...   \n",
       "1  chicken fish sauce onion cloves garlic lemongr...   \n",
       "2  pork blade steaks boneless light brown sugar g...   \n",
       "3  chicken thighs skin deboned oil cloves garlic ...   \n",
       "4  marrow bones beef bone beef water onion half g...   \n",
       "\n",
       "                                       cleanTextList  \\\n",
       "0  [beef, broth, water, yellow, onion, cloves, ga...   \n",
       "1  [chicken, fish, sauce, onion, cloves, garlic, ...   \n",
       "2  [pork, blade, steaks, boneless, light, brown, ...   \n",
       "3  [chicken, thighs, skin, deboned, oil, cloves, ...   \n",
       "4  [marrow, bones, beef, bone, beef, water, onion...   \n",
       "\n",
       "                                              parsed  \n",
       "0  (beef, broth, water, yellow, onion, cloves, ga...  \n",
       "1  (chicken, fish, sauce, onion, cloves, garlic, ...  \n",
       "2  (pork, blade, steaks, boneless, light, brown, ...  \n",
       "3  (chicken, thighs, skin, deboned, oil, cloves, ...  \n",
       "4  (marrow, bones, beef, bone, beef, water, onion...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words to Remove \n",
    "This code and these word lists are copied over as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/l/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Source for list below\n",
    "#https://en.wikipedia.org/wiki/Cooking_weights_and_measures\n",
    "#https://thebakingpan.com/ingredient-weights-and-measures/\n",
    "measures=['ounces','tablespoons','litrbes','liter','millilitres','mL','grams','g', 'kg','teaspoon','tsp', 'tablespoon','tbsp','fluid', 'ounce','oz','fl.oz', 'cup','pint','pt','quart','qt','gallon','gal','smidgen','drop','pinch','dash','scruple','dessertspoon','teacup','cup','cups','c','pottle','gill','dram','wineglass','coffeespoon','pound','pounded','lb','tbsp','plus','firmly', 'packed','lightly','level','even','rounded','heaping','heaped','sifted','bushel','peck','stick','chopped','sliced','halves', 'shredded','slivered','sliced','whole','paste','whole',' fresh', 'peeled', 'diced','mashed','dried','frozen','fresh','peeled','candied','no', 'pulp','crystallized','canned','crushed','minced','julienned','clove','head', 'small','large','medium', 'torn', 'cleaned', 'degree']\n",
    "\n",
    "#measures = [lemmatizer.lemmatize(m) for m in measures]\n",
    "#some of these include data leakage words, like 'italian' - ok to remove after including bigrams\n",
    "data_leaks = ['iberic','greek', 'korean','italianstyle', 'french','thai', 'chinese', 'mexican','spanish','indian','italian']\n",
    "\n",
    "common_remove=['ground','to','taste', 'and', 'or',  'can',  'into', 'cut', 'grated', 'leaf','package','finely','divided','a','piece','optional','inch','needed','more','drained','for','flake','dry','thinly','cubed','bunch','cube','slice','pod','beaten','seeded','uncooked','root','plain','heavy','halved','crumbled','sweet','with','hot','room','temperature','trimmed','allpurpose','deveined','bulk','seasoning','jar','food','if','bag','mix','in','each','roll','instant','double','such','frying','thawed','whipping','stock','rinsed','mild','sprig','freshly','toasted','link','boiling','cooked','unsalted','container',\n",
    "'cooking','thin','lengthwise','warm','softened','thick','quartered','juiced','pitted','chunk','melted','cold','coloring','puree','cored','stewed','floret','coarsely','the','blanched','zested','sweetened','powdered','garnish','dressing','soup','at','active','lean','chip','sour','long','ripe','skinned','fillet','from','stem','flaked','removed','stalk','unsweetened','cover','crust', 'extra', 'prepared', 'blend', 'of', 'ring',  'undrained', 'about', 'zest', ' ', '', 'spray', 'round', 'herb', 'seasoned', 'wedge', 'bitesize', 'broken', 'square', 'freshly', 'thickly', 'diagonally']\n",
    "#common_remove = [lemmatizer.lemmatize(c) for c in common_remove]\n",
    "#data_leaks = [lemmatizer.lemmatize(d) for d in data_leaks]\n",
    "# due to using bigrams not including \n",
    "useless_singles=['','black','white','red','yellow','seed','breast','confectioner','sundried','broth','bell','baby','juice','crumb','sauce','condensed','smoked','basmati','extravirgin','brown','clarified', 'soy', 'filling', 'pine', 'virgin', 'romano', 'heart', 'shell', 'thigh', 'boneless','skinless','split', 'dark', 'wheat', 'light', 'green', 'vegetable', 'curry', 'orange', 'garam', 'sesame', 'strip', 'sea', 'canola', 'mustard','powder', 'ice', 'bay', 'roasted', 'loaf', 'roast', 'powder']\n",
    "useless_singles = [lemmatizer.lemmatize(u) for u in useless_singles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanTextList</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vietnamese Pho Soup</td>\n",
       "      <td>['8 cups beef broth', '4 cups water', '1 yello...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>beef broth water yellow onion cloves garlic ro...</td>\n",
       "      <td>[beef, broth, water, yellow, onion, cloves, ga...</td>\n",
       "      <td>(beef, broth, water, yellow, onion, cloves, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Vietnamese Chicken Meatballs</td>\n",
       "      <td>['1 pound ground chicken', '3 tablespoons fish...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>chicken fish sauce onion cloves garlic lemongr...</td>\n",
       "      <td>[chicken, fish, sauce, onion, cloves, garlic, ...</td>\n",
       "      <td>(chicken, fish, sauce, onion, cloves, garlic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Vietnamese Restaurant-Style Grilled Lemongrass...</td>\n",
       "      <td>['1 pound pork blade steaks (boneless, about 1...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>pork blade steaks boneless light brown sugar g...</td>\n",
       "      <td>[pork, blade, steaks, boneless, light, brown, ...</td>\n",
       "      <td>(pork, blade, steaks, boneless, light, brown, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Vietnamese Caramel Chicken</td>\n",
       "      <td>['1 pound chicken thighs (with skin, deboned)'...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>chicken thighs skin deboned oil cloves garlic ...</td>\n",
       "      <td>[chicken, thighs, skin, deboned, oil, cloves, ...</td>\n",
       "      <td>(chicken, thighs, skin, deboned, oil, cloves, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Cheater Vietnamese Pho (Pho Bo)</td>\n",
       "      <td>['3 marrow bones (beef bone)', '50 ounces beef...</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>marrow bones beef bone beef water onion half g...</td>\n",
       "      <td>[marrow, bones, beef, bone, beef, water, onion...</td>\n",
       "      <td>(marrow, bones, beef, bone, beef, water, onion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                               name  \\\n",
       "0           1      1                                Vietnamese Pho Soup   \n",
       "1           2      2                       Vietnamese Chicken Meatballs   \n",
       "2           3      3  Vietnamese Restaurant-Style Grilled Lemongrass...   \n",
       "3           4      4                         Vietnamese Caramel Chicken   \n",
       "4           5      5                    Cheater Vietnamese Pho (Pho Bo)   \n",
       "\n",
       "                                         ingredients     cuisine  \\\n",
       "0  ['8 cups beef broth', '4 cups water', '1 yello...  Vietnamese   \n",
       "1  ['1 pound ground chicken', '3 tablespoons fish...  Vietnamese   \n",
       "2  ['1 pound pork blade steaks (boneless, about 1...  Vietnamese   \n",
       "3  ['1 pound chicken thighs (with skin, deboned)'...  Vietnamese   \n",
       "4  ['3 marrow bones (beef bone)', '50 ounces beef...  Vietnamese   \n",
       "\n",
       "                                           cleanText  \\\n",
       "0  beef broth water yellow onion cloves garlic ro...   \n",
       "1  chicken fish sauce onion cloves garlic lemongr...   \n",
       "2  pork blade steaks boneless light brown sugar g...   \n",
       "3  chicken thighs skin deboned oil cloves garlic ...   \n",
       "4  marrow bones beef bone beef water onion half g...   \n",
       "\n",
       "                                       cleanTextList  \\\n",
       "0  [beef, broth, water, yellow, onion, cloves, ga...   \n",
       "1  [chicken, fish, sauce, onion, cloves, garlic, ...   \n",
       "2  [pork, blade, steaks, boneless, light, brown, ...   \n",
       "3  [chicken, thighs, skin, deboned, oil, cloves, ...   \n",
       "4  [marrow, bones, beef, bone, beef, water, onion...   \n",
       "\n",
       "                                              parsed  \n",
       "0  (beef, broth, water, yellow, onion, cloves, ga...  \n",
       "1  (chicken, fish, sauce, onion, cloves, garlic, ...  \n",
       "2  (pork, blade, steaks, boneless, light, brown, ...  \n",
       "3  (chicken, thighs, skin, deboned, oil, cloves, ...  \n",
       "4  (marrow, bones, beef, bone, beef, water, onion...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    filtered_words = [w for w in filtered_words if not w in measures]\n",
    "    filtered_words = [w for w in filtered_words if not w in data_leaks]\n",
    "    filtered_words = [w for w in filtered_words if not w in common_remove]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "# Apply to the DF series\n",
    "df['cleanText']=df['ingredients'].map(lambda s:preprocess(s)) \n",
    "df['cleanTextList']=df['ingredients'].map(lambda s:preprocess(s).split()) \n",
    "df['parsed'] = df.cleanText.apply(nlp)\n",
    "df.sample(10)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>cleanTextList</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>377</td>\n",
       "      <td>377</td>\n",
       "      <td>Portuguese_Scallops</td>\n",
       "      <td>['1 pound sea scallops (fresh)', '1 teaspoon s...</td>\n",
       "      <td>Iberic</td>\n",
       "      <td>sea scallops salt black pepper olive oil port ...</td>\n",
       "      <td>[sea, scallops, salt, black, pepper, olive, oi...</td>\n",
       "      <td>(sea, scallops, salt, black, pepper, olive, oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "      <td>Portuguese_Grilled_Pork_Ribs</td>\n",
       "      <td>['4 pork rib (strips)', '500 milliliters white...</td>\n",
       "      <td>Iberic</td>\n",
       "      <td>pork rib strips milliliters white wine cloves ...</td>\n",
       "      <td>[pork, rib, strips, milliliters, white, wine, ...</td>\n",
       "      <td>(pork, rib, strips, milliliters, white, wine, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>393</td>\n",
       "      <td>393</td>\n",
       "      <td>Spanish_Rice</td>\n",
       "      <td>['1 cup long grain rice', '1 pound lean ground...</td>\n",
       "      <td>Iberic</td>\n",
       "      <td>grain rice beef onion vegetable oil bacon drip...</td>\n",
       "      <td>[grain, rice, beef, onion, vegetable, oil, bac...</td>\n",
       "      <td>(grain, rice, beef, onion, vegetable, oil, bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>Chinese_Fried_Rice</td>\n",
       "      <td>['2 tablespoons butter (divided)', '2 eggs (be...</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>butter eggs yellow onion carrots peas cloves g...</td>\n",
       "      <td>[butter, eggs, yellow, onion, carrots, peas, c...</td>\n",
       "      <td>(butter, eggs, yellow, onion, carrots, peas, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>Portuguese_Bacalhau</td>\n",
       "      <td>['1 pound salted cod (soaked in cold water for...</td>\n",
       "      <td>Iberic</td>\n",
       "      <td>salted cod soaked water hours potatoes white y...</td>\n",
       "      <td>[salted, cod, soaked, water, hours, potatoes, ...</td>\n",
       "      <td>(salted, cod, soaked, water, hours, potatoes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>335</td>\n",
       "      <td>Sesame_Chinese_Chicken_with_Rice</td>\n",
       "      <td>['4 skinless chicken breasts (boneless)', 'sal...</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>skinless chicken breasts boneless salt pepper ...</td>\n",
       "      <td>[skinless, chicken, breasts, boneless, salt, p...</td>\n",
       "      <td>(skinless, chicken, breasts, boneless, salt, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>349</td>\n",
       "      <td>349</td>\n",
       "      <td>Chinese_Green_Beans_with_Ground_Turkey</td>\n",
       "      <td>['1 cup medium grain rice (uncooked)', '1 tabl...</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>grain rice sesame oil green onions cloves garl...</td>\n",
       "      <td>[grain, rice, sesame, oil, green, onions, clov...</td>\n",
       "      <td>(grain, rice, sesame, oil, green, onions, clov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "      <td>Chinese_Chicken_and_Broccoli</td>\n",
       "      <td>['1 head broccoli (cut into florets)', '3 tabl...</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>broccoli florets vegetable oil boneless chicke...</td>\n",
       "      <td>[broccoli, florets, vegetable, oil, boneless, ...</td>\n",
       "      <td>(broccoli, florets, vegetable, oil, boneless, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>Spanish_Omelette</td>\n",
       "      <td>['1 pound potato (/ 3 medium potatoes, washed ...</td>\n",
       "      <td>Iberic</td>\n",
       "      <td>potato potatoes washed eggs onion olive oil to...</td>\n",
       "      <td>[potato, potatoes, washed, eggs, onion, olive,...</td>\n",
       "      <td>(potato, potatoes, washed, eggs, onion, olive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "      <td>Chinese_Chicken_Stir_Fry</td>\n",
       "      <td>['1 teaspoon chili oil', '2 cloves garlic (min...</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>chili oil cloves garlic ginger spring onions w...</td>\n",
       "      <td>[chili, oil, cloves, garlic, ginger, spring, o...</td>\n",
       "      <td>(chili, oil, cloves, garlic, ginger, spring, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  index                                    name  \\\n",
       "376         377    377                     Portuguese_Scallops   \n",
       "373         374    374            Portuguese_Grilled_Pork_Ribs   \n",
       "392         393    393                            Spanish_Rice   \n",
       "302         303    303                      Chinese_Fried_Rice   \n",
       "372         373    373                     Portuguese_Bacalhau   \n",
       "334         335    335        Sesame_Chinese_Chicken_with_Rice   \n",
       "348         349    349  Chinese_Green_Beans_with_Ground_Turkey   \n",
       "324         325    325            Chinese_Chicken_and_Broccoli   \n",
       "394         395    395                        Spanish_Omelette   \n",
       "349         350    350                Chinese_Chicken_Stir_Fry   \n",
       "\n",
       "                                           ingredients  cuisine  \\\n",
       "376  ['1 pound sea scallops (fresh)', '1 teaspoon s...   Iberic   \n",
       "373  ['4 pork rib (strips)', '500 milliliters white...   Iberic   \n",
       "392  ['1 cup long grain rice', '1 pound lean ground...   Iberic   \n",
       "302  ['2 tablespoons butter (divided)', '2 eggs (be...  Chinese   \n",
       "372  ['1 pound salted cod (soaked in cold water for...   Iberic   \n",
       "334  ['4 skinless chicken breasts (boneless)', 'sal...  Chinese   \n",
       "348  ['1 cup medium grain rice (uncooked)', '1 tabl...  Chinese   \n",
       "324  ['1 head broccoli (cut into florets)', '3 tabl...  Chinese   \n",
       "394  ['1 pound potato (/ 3 medium potatoes, washed ...   Iberic   \n",
       "349  ['1 teaspoon chili oil', '2 cloves garlic (min...  Chinese   \n",
       "\n",
       "                                             cleanText  \\\n",
       "376  sea scallops salt black pepper olive oil port ...   \n",
       "373  pork rib strips milliliters white wine cloves ...   \n",
       "392  grain rice beef onion vegetable oil bacon drip...   \n",
       "302  butter eggs yellow onion carrots peas cloves g...   \n",
       "372  salted cod soaked water hours potatoes white y...   \n",
       "334  skinless chicken breasts boneless salt pepper ...   \n",
       "348  grain rice sesame oil green onions cloves garl...   \n",
       "324  broccoli florets vegetable oil boneless chicke...   \n",
       "394  potato potatoes washed eggs onion olive oil to...   \n",
       "349  chili oil cloves garlic ginger spring onions w...   \n",
       "\n",
       "                                         cleanTextList  \\\n",
       "376  [sea, scallops, salt, black, pepper, olive, oi...   \n",
       "373  [pork, rib, strips, milliliters, white, wine, ...   \n",
       "392  [grain, rice, beef, onion, vegetable, oil, bac...   \n",
       "302  [butter, eggs, yellow, onion, carrots, peas, c...   \n",
       "372  [salted, cod, soaked, water, hours, potatoes, ...   \n",
       "334  [skinless, chicken, breasts, boneless, salt, p...   \n",
       "348  [grain, rice, sesame, oil, green, onions, clov...   \n",
       "324  [broccoli, florets, vegetable, oil, boneless, ...   \n",
       "394  [potato, potatoes, washed, eggs, onion, olive,...   \n",
       "349  [chili, oil, cloves, garlic, ginger, spring, o...   \n",
       "\n",
       "                                                parsed  \n",
       "376  (sea, scallops, salt, black, pepper, olive, oi...  \n",
       "373  (pork, rib, strips, milliliters, white, wine, ...  \n",
       "392  (grain, rice, beef, onion, vegetable, oil, bac...  \n",
       "302  (butter, eggs, yellow, onion, carrots, peas, c...  \n",
       "372  (salted, cod, soaked, water, hours, potatoes, ...  \n",
       "334  (skinless, chicken, breasts, boneless, salt, p...  \n",
       "348  (grain, rice, sesame, oil, green, onions, clov...  \n",
       "324  (broccoli, florets, vegetable, oil, boneless, ...  \n",
       "394  (potato, potatoes, washed, eggs, onion, olive,...  \n",
       "349  (chili, oil, cloves, garlic, ginger, spring, o...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only our cuisines\n",
    "new_df = df.loc[(df['cuisine'] == 'Chinese') | (df['cuisine'] == 'Iberic')]\n",
    "new_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scattertext.ParsedCorpus.ParsedCorpus object at 0x7f53d8e0abe0>\n"
     ]
    }
   ],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(new_df, category_col='cuisine', parsed_col='parsed').build()\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scale() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2000d6c2fe36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m html = produce_scattertext_explorer(corpus,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Chinese'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mcategory_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Chinese'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mnot_category_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Iberic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scattertext/__init__.py\u001b[0m in \u001b[0;36mproduce_scattertext_explorer\u001b[0;34m(corpus, category, category_name, not_category_name, protocol, pmi_threshold_coefficient, minimum_term_frequency, minimum_not_category_term_frequency, max_terms, filter_unigrams, height_in_pixels, width_in_pixels, max_snippets, max_docs_per_category, metadata, scores, x_coords, y_coords, original_x, original_y, rescale_x, rescale_y, singleScoreMode, sort_by_dist, reverse_sort_scores_for_not_category, use_full_doc, transform, jitter, gray_zero_scores, term_ranker, asian_mode, match_full_line, use_non_text_features, show_top_terms, show_characteristic, word_vec_use_p_vals, max_p_val, p_value_colors, term_significance, save_svg_button, x_label, y_label, d3_url, d3_scale_chromatic_url, pmi_filter_thresold, alternative_text_field, terms_to_include, semiotic_square, num_terms_semiotic_square, not_categories, neutral_categories, extra_categories, show_neutral, neutral_category_name, get_tooltip_content, x_axis_values, y_axis_values, x_axis_values_format, y_axis_values_format, color_func, term_scorer, show_axes, show_axes_and_cross_hairs, show_diagonal, use_global_scale, horizontal_line_y_position, vertical_line_x_position, show_cross_axes, show_extra, extra_category_name, censor_points, center_label_over_points, x_axis_labels, y_axis_labels, topic_model_term_lists, topic_model_preview_size, metadata_descriptions, vertical_lines, characteristic_scorer, term_colors, unified_context, show_category_headings, highlight_selected_category, include_term_category_counts, div_name, alternative_term_func, term_metadata, term_metadata_df, max_overlapping, include_all_contexts, show_corpus_stats, sort_doc_labels_by_name, enable_term_category_description, always_jump, get_custom_term_html, header_names, header_sorting_algos, ignore_categories, d3_color_scale, background_labels, tooltip_columns, tooltip_column_names, term_description_columns, term_description_column_names, term_word_in_term_description, color_column, color_score_column, label_priority_column, text_color_column, suppress_text_column, background_color, left_list_column, censor_point_column, right_order_column, line_coordinates, subword_encoding, use_offsets, return_data, return_scatterplot_structure)\u001b[0m\n\u001b[1;32m    592\u001b[0m         html_base = get_semiotic_square_html(num_terms_semiotic_square,\n\u001b[1;32m    593\u001b[0m                                              semiotic_square)\n\u001b[0;32m--> 594\u001b[0;31m     scatter_chart_data = scatter_chart_explorer.to_dict(\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mcategory_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scattertext/ScatterChartExplorer.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, category, category_name, not_category_name, scores, metadata, max_docs_per_category, transform, alternative_text_field, title_case_names, not_categories, neutral_categories, extra_categories, neutral_category_name, extra_category_name, background_scorer, include_term_category_counts, use_offsets, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Excessive arguments passed to ScatterChartExplorer.to_dict: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         json_data = ScatterChart.to_dict(self,\n\u001b[0m\u001b[1;32m    116\u001b[0m                                          \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                                          \u001b[0mcategory_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scattertext/ScatterChart.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, category, category_name, not_category_name, scores, transform, title_case_names, not_categories, neutral_categories, extra_categories, background_scorer, use_offsets, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_coords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_coordinates_from_transform_and_jitter_frequencies\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scattertext/ScatterChart.py\u001b[0m in \u001b[0;36m_get_coordinates_from_transform_and_jitter_frequencies\u001b[0;34m(self, category, df, other_categories, transform)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mnot_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' freq'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_categories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mx_data_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0my_data_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_jitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scale() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='Chinese',\n",
    "                                    category_name='Chinese',\n",
    "                                    not_category_name='Iberic',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    transform=st.Scalers.scale,\n",
    "                                    metadata=new_df['name'])\n",
    "file_name = 'output/ChineseIbericCusineScattertextScale.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram function based on spacy\n",
    "def bigram(doc):\n",
    "    # create a list for the result\n",
    "    result = list()\n",
    "    # create a list that contains no punctuation\n",
    "    sentence = list()\n",
    "    # parse through the document to add all tokens that are words to the sentence list\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            sentence.append(token)\n",
    "    # parse through the sentence while adding words in groups of two to the result\n",
    "    for word in range(len(sentence) - 1):\n",
    "        first_word = sentence[word]\n",
    "        second_word = sentence[word + 1]\n",
    "        element = [first_word.text, second_word.text]\n",
    "        result.append(element)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(text):\n",
    "    # load English model\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "    # create a document\n",
    "    doc = nlp(text)\n",
    "\n",
    "    result = bigram(doc)\n",
    "    bigrams = ''\n",
    "    for element in result:\n",
    "        joined_string = \" \".join(element)\n",
    "        js = joined_string + \",\"\n",
    "        bigrams = bigrams + js\n",
    "        \n",
    "    \n",
    "    return bigrams\n",
    "    \n",
    "\n",
    "new_df['bigrams'] = new_df['cleanText'].apply(generate_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute number of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['num_ing'] = [len(x.split()) for x in new_df['cleanText'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = new_df['num_ing'].sum()\n",
    "Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative number of different ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['rel_ing'] = new_df['num_ing'].div(Total)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top10 most common ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(\" \".join(new_df[\"cleanText\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors: \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(new_df['cleanText'], 10)\n",
    "\n",
    "df1 = pd.DataFrame(common_words, columns = ['word' , 'count'])\n",
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df1.plot.bar(x='word',y='count', color=['coral'], alpha=0.8,  fontsize=20, figsize=(20, 8),edgecolor = \"grey\", grid= True)\n",
    "plt.xlabel('Words', fontsize=40)\n",
    "plt.ylabel('Frequenz', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top10 most frequent ingredient bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['cleanText'], 10)\n",
    "\n",
    "df2 = pd.DataFrame(common_words, columns = ['words' , 'count'])\n",
    "\n",
    "df2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df2.plot.bar(x='words',y='count', color=['coral'], alpha=0.8,  fontsize=20, figsize=(20, 8),edgecolor = \"grey\", grid= True)\n",
    "plt.xlabel('Words', fontsize=40)\n",
    "plt.ylabel('Frequenz', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df['parsed'].iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "a_list= new_df['cleanTextList']\n",
    "# a_list = ['hund','katze', 'maus']\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for i in a_list:\n",
    "    for pair in itertools.combinations(i,2):\n",
    "        pairs.append(pair)\n",
    "\n",
    "print(pairs[0:10])\n",
    "\n",
    "    \n",
    "from collections import Counter\n",
    "Counter(elem[0:2] for elem in pairs).most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BigData Task 2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMJ5a9GtMbomLZqzSDidFAB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjYzvTVmwjsO","executionInfo":{"status":"ok","timestamp":1624615697921,"user_tz":-120,"elapsed":2944,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"c70180e5-6c0b-45ad-deef-9c09579fd6fb"},"source":["import pandas as pd\n","import numpy as np \n","import seaborn as sns\n","import csv\n","import matplotlib.pyplot as plt \n","import collections\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","### Metrics\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","### Gridsearch\n","from pprint import pprint\n","from time import time\n","import logging\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","### Classifiers\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zt3Myf36xL5N","executionInfo":{"status":"ok","timestamp":1624615718133,"user_tz":-120,"elapsed":20214,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"ef685154-4f9f-470d-cee0-bd7bbb49a19f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/Colab Notebooks/\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKgVldcrz7NT","executionInfo":{"status":"ok","timestamp":1624616020157,"user_tz":-120,"elapsed":212,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"b0dd2b73-b480-4adf-a7d9-dda1ad03b911"},"source":["%cd /content/drive/My Drive/Colab Notebooks/\n","train = pd.read_csv(\"train_data_w_ingredients.csv\", sep=';', error_bad_lines=False, index_col=0)\n","test = pd.read_csv(\"test_data_w_ingredients.csv\", sep=';', error_bad_lines=False, index_col=0)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"I45QpL8O0GWk","executionInfo":{"status":"ok","timestamp":1624616021558,"user_tz":-120,"elapsed":214,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"79eb9cb0-041a-4879-8227-59a35004b070"},"source":["train.drop([\"index\"], axis=1, inplace=True)\n","train.drop([\"name\"], axis=1, inplace=True)\n","test.drop([\"index\"], axis=1, inplace=True)\n","test.drop([\"name\"], axis=1, inplace=True)\n","train.head(5)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ingredients</th>\n","      <th>cuisine</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>['8 cups beef broth', '4 cups water', '1 yello...</td>\n","      <td>Vietnamese</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['1 pound ground chicken', '3 tablespoons fish...</td>\n","      <td>Vietnamese</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['1 pound pork blade steaks (boneless, about 1...</td>\n","      <td>Vietnamese</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['1 pound chicken thighs (with skin, deboned)'...</td>\n","      <td>Vietnamese</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>['3 marrow bones (beef bone)', '50 ounces beef...</td>\n","      <td>Vietnamese</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         ingredients     cuisine\n","1  ['8 cups beef broth', '4 cups water', '1 yello...  Vietnamese\n","2  ['1 pound ground chicken', '3 tablespoons fish...  Vietnamese\n","3  ['1 pound pork blade steaks (boneless, about 1...  Vietnamese\n","4  ['1 pound chicken thighs (with skin, deboned)'...  Vietnamese\n","5  ['3 marrow bones (beef bone)', '50 ounces beef...  Vietnamese"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"b34WtLkmJiN1","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1624616023880,"user_tz":-120,"elapsed":7,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"3c8ce6bd-5935-442f-edd4-5257385eca52"},"source":["test.head(5)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ingredients</th>\n","      <th>cuisine</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>['1/4 cup liquid', '15.5 ounces garbanzo beans...</td>\n","      <td>Greek</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['2 cups instant couscous', '1 cup water', '1 ...</td>\n","      <td>Greek</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['1 onion', '1 garlic clove', '3 tablespoons o...</td>\n","      <td>Greek</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['1 pound ground beef', '1 pound ground lamb',...</td>\n","      <td>Greek</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>['1 pound yellow potatoes (baby Dutch)', '1 po...</td>\n","      <td>Greek</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         ingredients cuisine\n","1  ['1/4 cup liquid', '15.5 ounces garbanzo beans...   Greek\n","2  ['2 cups instant couscous', '1 cup water', '1 ...   Greek\n","3  ['1 onion', '1 garlic clove', '3 tablespoons o...   Greek\n","4  ['1 pound ground beef', '1 pound ground lamb',...   Greek\n","5  ['1 pound yellow potatoes (baby Dutch)', '1 po...   Greek"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"Rb7e4uST09LE","executionInfo":{"status":"ok","timestamp":1624616028480,"user_tz":-120,"elapsed":2552,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"d87eddd8-7ca9-48ee-c04b-20d0946eae6c"},"source":["lemmatizer = WordNetLemmatizer()\n","\n","def preprocess(text):\n","    text=str(text) #stringify\n","    text = text.lower() #kleinschreibung\n","    text = re.sub(\"\\(.*?\\)\",\"()\",text) #Alternativen entfernen - also alles zwischen ( )\n","    text=text.replace('{html}',\"\") \n","    cleanr = re.compile('<.*?>')\n","    cleantext = re.sub(cleanr, '', text)\n","    rem_url=re.sub(r'http\\S+', '',cleantext)\n","    rem_num = re.sub('[0-9]+', '', rem_url)\n","    tokenizer = RegexpTokenizer(r'\\w+')\n","    tokens = tokenizer.tokenize(rem_num)\n","    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n","    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words] \n","    \"\"\"lemma_words = [w for w in lemma_words if not w in measures]\n","    lemma_words = [w for w in lemma_words if not w in data_leaks]\n","    lemma_words = [w for w in lemma_words if not w in common_remove]\n","    lemma_words = [w for w in lemma_words if not w in useless_singles]\"\"\"\n","    \n","    return \" \".join(lemma_words)\n","\n","\n","# Apply to the DF series\n","train['cleanText']=train['ingredients'].map(lambda s:preprocess(s)) \n","train.drop([\"ingredients\"], axis=1, inplace=True)\n","test['cleanText']=test['ingredients'].map(lambda s:preprocess(s)) \n","test.drop([\"ingredients\"], axis=1, inplace=True)\n","train.head(3)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cuisine</th>\n","      <th>cleanText</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Vietnamese</td>\n","      <td>cup beef broth cup water yellow onion clove ga...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vietnamese</td>\n","      <td>pound ground chicken tablespoon fish sauce oni...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Vietnamese</td>\n","      <td>pound pork blade steak tablespoon light brown ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      cuisine                                          cleanText\n","1  Vietnamese  cup beef broth cup water yellow onion clove ga...\n","2  Vietnamese  pound ground chicken tablespoon fish sauce oni...\n","3  Vietnamese  pound pork blade steak tablespoon light brown ..."]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"zJilw8jJCnNU","executionInfo":{"status":"ok","timestamp":1624615723001,"user_tz":-120,"elapsed":7,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}}},"source":["X_train = train['cleanText']\n","y_train = train['cuisine']\n","\n","X_test = test['cleanText']\n","y_test = test['cuisine']"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"id":"P-Uclzdi2MPN","executionInfo":{"status":"error","timestamp":1624615763930,"user_tz":-120,"elapsed":40934,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"fb1a6df0-ea74-44e9-ee28-af2ae0f0486c"},"source":["# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n","\n","data = train\n","\n","\n","# #############################################################################\n","# Define a pipeline combining a text feature extractor with a simple\n","# classifier\n","pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', SGDClassifier()),\n","])\n","\n","# uncommenting more parameters will give better exploring power but will\n","# increase processing time in a combinatorial way\n","parameters = {\n","    'vect__max_df': (0.5, 0.75, 1.0),\n","    'vect__max_features': (None, 5000, 10000, 50000),\n","    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n","    'tfidf__use_idf': (True, False),\n","    'tfidf__norm': ('l1', 'l2'),\n","    'clf__max_iter': (20,),\n","    'clf__alpha': (0.00001, 0.000001),\n","    'clf__penalty': ('l2', 'elasticnet'),\n","    'clf__max_iter': (10, 50, 80),\n","    \n","}\n","\n","if __name__ == \"__main__\":\n","    # multiprocessing requires the fork to happen in a __main__ protected\n","    # block\n","\n","    # find the best parameters for both the feature extraction and the\n","    # classifier\n","    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n","\n","    print(\"Performing grid search...\")\n","    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n","    print(\"parameters:\")\n","    pprint(parameters)\n","    t0 = time()\n","    grid_search.fit(data.cleanText, data.cuisine)\n","    print(\"done in %0.3fs\" % (time() - t0))\n","    print()\n","\n","    print(\"Best score: %0.3f\" % grid_search.best_score_)\n","    print(\"Best parameters set:\")\n","    best_parameters = grid_search.best_estimator_.get_params()\n","    for param_name in sorted(parameters.keys()):\n","        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Performing grid search...\n","pipeline: ['vect', 'tfidf', 'clf']\n","parameters:\n","{'clf__alpha': (1e-05, 1e-06),\n"," 'clf__max_iter': (10, 50, 80),\n"," 'clf__penalty': ('l2', 'elasticnet'),\n"," 'tfidf__norm': ('l1', 'l2'),\n"," 'tfidf__use_idf': (True, False),\n"," 'vect__max_df': (0.5, 0.75, 1.0),\n"," 'vect__max_features': (None, 5000, 10000, 50000),\n"," 'vect__ngram_range': ((1, 1), (1, 2))}\n","Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    5.2s\n","[Parallel(n_jobs=-1)]: Done 716 tasks      | elapsed:   24.9s\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-cc473d622f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuisine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTnW2tN5-zXE","executionInfo":{"status":"ok","timestamp":1624615780733,"user_tz":-120,"elapsed":254,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"553e75f4-fe3f-45f2-bdff-d8e2f4d632b3"},"source":["nb = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', MultinomialNB()),\n","              ])\n","nb.fit(X_train, y_train)\n","\n","y_pred = nb.predict(X_train)\n","\n","print('accuracy %s' % accuracy_score(y_pred, y_train))\n","print(classification_report(y_train, y_pred))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["accuracy 0.8775\n","              precision    recall  f1-score   support\n","\n","     Chinese       0.84      0.98      0.91        60\n","       Greek       0.71      0.98      0.82        50\n","      Iberic       1.00      0.47      0.64        40\n","     Italian       0.98      0.96      0.97        50\n","        Thai       0.87      0.90      0.88        50\n","  Vietnamese       0.98      0.80      0.88        50\n","      french       0.87      0.90      0.88        50\n","      korean       0.96      0.92      0.94        50\n","\n","    accuracy                           0.88       400\n","   macro avg       0.90      0.86      0.87       400\n","weighted avg       0.90      0.88      0.87       400\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTnqGEhtDbki","executionInfo":{"status":"ok","timestamp":1624615783102,"user_tz":-120,"elapsed":254,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"cc7df23e-9335-4da9-bc9a-959d0c712b4c"},"source":["knn = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', KNeighborsClassifier()),\n","              ])\n","knn.fit(X_train, y_train)\n","\n","y_pred = knn.predict(X_train)\n","\n","print('accuracy %s' % accuracy_score(y_pred, y_train))\n","print(classification_report(y_train, y_pred))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["accuracy 0.835\n","              precision    recall  f1-score   support\n","\n","     Chinese       0.80      0.92      0.85        60\n","       Greek       0.75      0.96      0.84        50\n","      Iberic       0.83      0.60      0.70        40\n","     Italian       0.87      0.82      0.85        50\n","        Thai       0.78      0.94      0.85        50\n","  Vietnamese       1.00      0.68      0.81        50\n","      french       0.90      0.90      0.90        50\n","      korean       0.85      0.80      0.82        50\n","\n","    accuracy                           0.83       400\n","   macro avg       0.85      0.83      0.83       400\n","weighted avg       0.85      0.83      0.83       400\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2y-aHhI8ERqf","executionInfo":{"status":"ok","timestamp":1624615841636,"user_tz":-120,"elapsed":198,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}}},"source":["names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n","         \"Decision Tree\", \"Random Forest\", \"Neural Net\",\n","         \"AdaBoost\", \"multinomial Naive Bayes\",\"SGD\"]\n","\n","classifiers = [\n","    KNeighborsClassifier(3),\n","    SVC(kernel=\"linear\", C=0.025),\n","    SVC(gamma=2, C=1),\n","    DecisionTreeClassifier(max_depth=5),\n","    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n","    MLPClassifier(alpha=1, max_iter=1000),\n","    AdaBoostClassifier(),\n","    MultinomialNB(),\n","    SGDClassifier()]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AM4QaDvOEarF","executionInfo":{"status":"ok","timestamp":1624615897924,"user_tz":-120,"elapsed":4237,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"82e85c46-ce6f-47f6-b868-1b974415c1e1"},"source":["# iterate over classifiers\n","for name, clf in zip(names, classifiers):\n","\n","    pipeline = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', clf),\n","              ])\n","    pipeline.fit(X_train, y_train)\n","    \n","    y_pred = pipeline.predict(X_test)\n","    print('**************')\n","    print(name)\n","    print('accuracy %s' % accuracy_score(y_pred, y_test))\n","    #print(classification_report(y_test, y_pred))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["**************\n","Nearest Neighbors\n","accuracy 0.775\n","**************\n","Linear SVM\n","accuracy 0.125\n","**************\n","RBF SVM\n","accuracy 0.9\n","**************\n","Decision Tree\n","accuracy 0.55\n","**************\n","Random Forest\n","accuracy 0.275\n","**************\n","Neural Net\n","accuracy 0.8\n","**************\n","AdaBoost\n","accuracy 0.35\n","**************\n","multinomial Naive Bayes\n","accuracy 0.625\n","**************\n","SGD\n","accuracy 0.825\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INWfKoCrHzha","executionInfo":{"status":"ok","timestamp":1624615905654,"user_tz":-120,"elapsed":196,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}},"outputId":"2a676167-62e3-4f7e-f9d7-f85e560bcc7b"},"source":["rbf_svm = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', SVC(gamma=2, C=1)),\n","              ])\n","rbf_svm.fit(X_train, y_train)\n","\n","y_pred = rbf_svm.predict(X_test)\n","\n","print('accuracy %s' % accuracy_score(y_pred, y_test))\n","print(classification_report(y_test, y_pred))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["accuracy 0.9\n","              precision    recall  f1-score   support\n","\n","     Chinese       1.00      1.00      1.00         5\n","       Greek       1.00      1.00      1.00         5\n","      Iberic       1.00      1.00      1.00         5\n","     Italian       0.80      0.80      0.80         5\n","        Thai       1.00      1.00      1.00         5\n","  Vietnamese       0.83      1.00      0.91         5\n","      french       0.67      0.80      0.73         5\n","      korean       1.00      0.60      0.75         5\n","\n","    accuracy                           0.90        40\n","   macro avg       0.91      0.90      0.90        40\n","weighted avg       0.91      0.90      0.90        40\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i8xgkfl2KLyj","executionInfo":{"status":"aborted","timestamp":1624615763929,"user_tz":-120,"elapsed":14,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}}},"source":["# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n","\n","data = train\n","\n","\n","# #############################################################################\n","# Define a pipeline combining a text feature extractor with a simple\n","# classifier\n","pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', SVC()),\n","])\n","\n","# uncommenting more parameters will give better exploring power but will\n","# increase processing time in a combinatorial way\n","# max combinations: 3x4x2x2x2x4x2x2= 1536\n","parameters = {\n","    'vect__max_df': (0.5, 0.75, 1.0),\n","    'vect__max_features': (None, 5000, 10000, 50000),\n","    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n","    'tfidf__use_idf': (True, False),\n","    'tfidf__norm': ('l1', 'l2'),\n","    'clf__C': (1, 10, 100, 1000),\n","    'clf__gamma': (0.001, 0.0001,1, 2),\n","    'clf__kernel': ('linear', 'rbf'), \n","}\n","\n","\"\"\"if __name__ == \"__main__\":\n","    # multiprocessing requires the fork to happen in a __main__ protected\n","    # block\n","\n","    # find the best parameters for both the feature extraction and the\n","    # classifier\n","    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n","\n","    print(\"Performing grid search...\")\n","    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n","    print(\"parameters:\")\n","    pprint(parameters)\n","    t0 = time()\n","    grid_search.fit(data.cleanText, data.cuisine)\n","    print(\"done in %0.3fs\" % (time() - t0))\n","    print()\n","\n","    print(\"Best score: %0.3f\" % grid_search.best_score_)\n","    print(\"Best parameters set:\")\n","    best_parameters = grid_search.best_estimator_.get_params()\n","    for param_name in sorted(parameters.keys()):\n","        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ESo5qxdRnEO","executionInfo":{"status":"aborted","timestamp":1624615763930,"user_tz":-120,"elapsed":15,"user":{"displayName":"Adrian Awad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8zPafWwtHZnc3owsA5p6KEMnU-Sy1m5Ae-zB0rw=s64","userId":"14575995503856564975"}}},"source":["# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n","\n","data = train\n","\n","\n","# #############################################################################\n","# Define a pipeline combining a text feature extractor with a simple\n","# classifier\n","pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', MLPClassifier()),\n","])\n","\n","# uncommenting more parameters will give better exploring power but will\n","# increase processing time in a combinatorial way\n","# max combinations: 3x4x2x2x2x4x2x2= 1536\n","parameters = {\n","    'vect__max_df': (0.5, 0.75, 1.0),\n","    'vect__max_features': (None, 5000, 10000, 50000),\n","    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n","    'tfidf__use_idf': (True, False),\n","    'tfidf__norm': ('l1', 'l2'),\n","    'clf__hidden_layer_sizes': [(10,30,10),(20,)],\n","    'clf__activation': ['tanh', 'relu'],\n","    'clf__solver': ['sgd', 'adam'],\n","    'clf__alpha': [0.0001, 0.05],\n","    'clf__learning_rate': ['constant','adaptive'], \n","}\n","\n","\"\"\"if __name__ == \"__main__\":\n","    # multiprocessing requires the fork to happen in a __main__ protected\n","    # block\n","\n","    # find the best parameters for both the feature extraction and the\n","    # classifier\n","    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=2)\n","\n","    print(\"Performing grid search...\")\n","    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n","    print(\"parameters:\")\n","    pprint(parameters)\n","    t0 = time()\n","    grid_search.fit(data.cleanText, data.cuisine)\n","    print(\"done in %0.3fs\" % (time() - t0))\n","    print()\n","\n","    print(\"Best score: %0.3f\" % grid_search.best_score_)\n","    print(\"Best parameters set:\")\n","    best_parameters = grid_search.best_estimator_.get_params()\n","    for param_name in sorted(parameters.keys()):\n","        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\"\"\""],"execution_count":null,"outputs":[]}]}